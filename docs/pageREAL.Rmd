---
title: |
  | Central Valley Enhanced
  | Acoustic Tagging Project
output:
  html_document:
    code_folding: hide
    toc: true
    toc_float: true
---
```{r setup, include=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyr)

```

```{r logos, echo=FALSE}
htmltools::img(src = knitr::image_uri("../data/NOAA logo.jpg"), 
               alt = 'logo', 
               style = 'position:absolute; top:0px; right:0px; width:100px;')
htmltools::img(src = knitr::image_uri("../data/BureauOfReclamation.png"), 
               alt = 'logo', 
               style = 'position:absolute; top:10px; right:110px; width:200px;')
```

<br/>


# *Real-time tracking Diagnostics*


```{r bring in data, massage, create new data files, print diagnostics, echo=FALSE, warning=FALSE, message=FALSE, results = "hide"}

library(knitr)
library(dplyr)
library(data.table)

dirs <- list.dirs(path= "C:/Advanced Telemetry Systems, Inc/ATS Trident Receiver/Data")
setwd(paste(file.path(Sys.getenv("USERPROFILE"),"Desktop",fsep="\\"), "\\Real-time data massaging\\products", sep = ""))

#ATS_processed_files <- read.csv("ATS_processed_files.csv", stringsAsFactors = F)
TECKNO_processed_files <- read.csv("TECKNO_processed_files.csv", stringsAsFactors = F)
gen_locs <- read.csv("realtime_locs.csv", stringsAsFactors = F)
gen_locs$recv <- as.character(gen_locs$recv)
downloads <- read.csv("downloads.csv", stringsAsFactors = FALSE)
downloads$end <- as.POSIXct(downloads$end, format = "%Y-%m-%d %H:%M:%S", tz = "Etc/GMT+8")
downloads$start <- as.POSIXct(downloads$start, format = "%Y-%m-%d %H:%M:%S", tz = "Etc/GMT+8")

corrupted_downloads <- read.csv("corrupted_downloads.csv", stringsAsFactors = F)
tagcodes <- read.csv("qry_HexCodes.txt", stringsAsFactors = F)
tagcodes$RelDT <- as.POSIXct(tagcodes$RelDT, format = "%m/%d/%Y %I:%M:%S %p", tz = "Etc/GMT+8")

detects <- fread("detects_final.csv", stringsAsFactors = FALSE)

detects$DateTime_PST <- as.POSIXct(detects$DateTime_PST, format = "%Y-%m-%d %H:%M:%OS")

## Find all Teckno file names
TECKNO_all_files <- as.data.frame(dir(pattern = "*.txt", path = "C:/Users/Trailer/Desktop/data", full.names = T))
colnames(TECKNO_all_files) <- "x"
TECKNO_all_files$x <- as.character(TECKNO_all_files$x)
## Select only newest TECKNO files for massaging
TECKNO_files <- as.data.frame(TECKNO_all_files[!TECKNO_all_files$x %in% TECKNO_processed_files$x,])
colnames(TECKNO_files) <- "x"
TECKNO_files$x <- as.character(TECKNO_files$x)

## Find all ATS file names
#ATS_all_files <- as.data.frame(dir(pattern = "*.csv", path = dirs, full.names = T))
#colnames(ATS_all_files) <- "x"
#ATS_all_files$x <- as.character(ATS_all_files$x)
## Select only newest ATS files for massaging
#ATS_files <- ATS_all_files[!ATS_all_files$x %in% ATS_processed_files$x,]
ATS_files <- data.frame()


#### Data massage ATS files first ####

downloads_new_all <- data.frame()

if (nrow(ATS_files) > 0) {
  downloads_new <- data.frame()
  for (i in 1:nrow(ATS_files)) {
    
    if (substr(read.csv(ATS_files[i,], nrows = 1, header = F)[,1] , 1,4) == "Site") {
      hour <- read.csv(ATS_files[i,], stringsAsFactors = F, skip = 7, nrows = 1, header = F)
      recv <- read.csv(ATS_files[i,], stringsAsFactors = F, skip = 2, nrows = 1, header = F)
    }
    else {
      recv <- read.csv(ATS_files[i,], stringsAsFactors = F, skip = 6, nrows = 1, header = F)
      hour <- read.csv(ATS_files[i,], stringsAsFactors = F, skip = 19, nrows = 1, header = F)
    }
    hour <- substr(hour, start = 13, stop = 31)
    recv <- substr(recv, start = 16, stop = 21)
    downloads_new <- rbind(downloads_new, cbind(recv, hour))
  }
  
  downloads_new$start <- as.POSIXct(downloads_new$hour, format = "%m/%d/%Y %H:%M:%S", tz = "Etc/GMT+8")
  downloads_new$end <- downloads_new$start +(60*60)
  downloads_new <-  merge(downloads_new, gen_locs,  by = "recv")

  downloads_new_all <- rbind(downloads_new_all, downloads_new)
  
  detects_new <- data.frame()
  corrupted_downloads_new <- NULL
  for (i in 1:nrow(ATS_files)) {
    if (substr(read.csv(ATS_files[i,], nrows = 1, header = F)[,1] , 1,4) == "Site") {
      test <- read.csv(ATS_files[i,], stringsAsFactors = F, skip = 9, header = T,  row.names=NULL)
    } else {
      test <- read.csv(ATS_files[i,], stringsAsFactors = F, skip = 22, header = T,  row.names=NULL)
    } 
    colnames(test) <- colnames(test)[-1]
    test[,ncol(test)] <- NULL
    test$recv <- substr(ATS_files[i,], nchar(ATS_files[i,])-22, nchar(ATS_files[i,])-18)
    end1 <- head(grep("--", test$Internal),1)
    end2 <- head(grep("File End", test$Internal),1)
    end_final <- head(grep(".-- Done", test$Internal),1)
  
    if (length(end_final) == 0) {
      corrupted_downloads_new <- rbind(corrupted_downloads_new, ATS_files[i,])
    } else {
      test1 <- test[-c(end_final:nrow(test)),]
      test2 <- test1[!test1$TagCode == "",]
      test3 <- test2[!test2$TagCode == " TagCode",]
      detects_new <- rbind(detects_new, test3)
    }
  }

  shortname <- regexpr(corrupted_downloads_new, pattern = "Data")[1]
  incomplete_shortname <- substr(corrupted_downloads_new, shortname+5, nchar(corrupted_downloads_new))
  corrupted <- strsplit(incomplete_shortname, "/")
  corrupted2 <- unlist(lapply(corrupted, tail, 1))
  corrupted_downloads <- rbind(corrupted_downloads,corrupted2)

  #locs <- detects_new[detects_new$TagCode == " GPS Fix  ",]
  #N <- unlist(gregexpr(pattern ='N',locs$Internal))
  #locs$lat <- as.numeric(substr(locs$Internal, start = 1, stop = N-1))
  #locs$lon <- as.numeric(substr(locs$Internal, start = N+1, stop= nchar(locs$Internal)-2))
  #locs$lat <- round(locs$lat, 0)/100
  #locs$lon <- round(locs$lon, 0)/100*-1
  
  #coords <- unique(locs[,c("recv", "lat", "lon")])
  
  detects_new <- detects_new[!detects_new$TagCode == " GPS Fix  ",]
  
  names(detects_new)[names(detects_new) == 'DateTime'] <- 'DateTime_Orig'
  
  detects_new$DateTime_PST <- as.POSIXct(detects_new$DateTime_Orig, format = "%m/%d/%Y %H:%M:%S.%OS", tz = "Etc/GMT+8")
  
  #detects_new <- merge(detects_new, coords, by = "recv", all.x = T)
  
  #detects_new <- merge(detects_new, gen_locs, by = "recv", all.x = T)
  
  detects <- rbind(detects, detects_new)
  
}




#### Now data massage TECKNO files ####





if (nrow(TECKNO_files) > 0) {
  downloads_new <- data.frame()
  for (i in 1:nrow(TECKNO_files)) {
    test <- try(read.csv(TECKNO_files[i,], header = F, stringsAsFactors = F ), silent = T) 
    if (inherits(test, "try-error")) {
      next
    } else {
      test1 <- tail(test[nchar(test$V5) > 4,],1)
      hour <- test1$V3
      recv <- test1$V1
      sun_volts <- test[1,"V17"]
      bat_volts <- test[1,"V18"]
      downloads_new <- rbind(downloads_new, cbind(recv, hour, sun_volts, bat_volts))
    }
  }

  downloads_new$end <- as.POSIXct(downloads_new$hour, tz = "GMT")
  downloads_new$start <- downloads_new$end -(60*60)
  downloads_new <-  merge(downloads_new, gen_locs[,c("recv", "location", "general_location", "latitude", "longitude", "rkm")],  by = "recv")

  
  ## Now change all times to PST to match ATS receivers
  attributes(downloads_new$start)$tzone <- "Etc/GMT+8"
  attributes(downloads_new$end)$tzone <- "Etc/GMT+8"

  downloads_new_all <- rbind(downloads_new_all, downloads_new)

  detects_new <- data.frame()

  ## Put in progress bar
  #pb <- txtProgressBar(min = 0, max = nrow(TECKNO_files), style = 3)
  
  for (i in 1:nrow(TECKNO_files)) {
    res <- try(read.csv(TECKNO_files[i,], header = F), silent = T) 
    if (inherits(res, "try-error")) {
      corrupted <- strsplit(TECKNO_files[i,], "/")
      corrupted2 <- unlist(lapply(corrupted, tail, 1))
      corrupted_downloads <- rbind(corrupted_downloads,corrupted2)
      ## Also make corrupted downloads more palateable
      next
    } else {
      start <- nchar(read.csv(TECKNO_files[i,],stringsAsFactors = F, header = F)$V5)
      start <- head(which(start==4),1)
      if (length(start) > 0) {
        test <- read.csv(TECKNO_files[i,], skip = start-1, header = F, stringsAsFactors = F )
        test1 <- test[nchar(test$V5)==4,]
        detects_new <- rbind(detects_new, test1[,1:9])
      
      }    
    }
    #setTxtProgressBar(pb, i)
  }
  #close(pb)
  
  colnames(detects_new) <- c("recv", "V2", "DateTime_Orig", "dec_seconds", "TagCode", "V6", "V7", "V8", "V9")
  detects_new <- detects_new[!detects_new$V2 == "N",]
  ## In this step, append datetime to milliseconds, but make sure the 6 decimal places are represented for all cases, even when there are trailering zeros
  detects_new$DateTime_Orig <- paste(detects_new$DateTime_Orig, substr(formatC(as.numeric(detects_new$dec_seconds),format='f', digits=6 ),2,8), sep = "")
  ## Make a POSIX class, note that TECKNO detections are in GMT, will need to convert to local time
  detects_new$DateTime_PST <- as.POSIXct(detects_new$DateTime_Orig, format = "%Y-%m-%d %H:%M:%OS", tz = "GMT")
  attributes(detects_new$DateTime_PST)$tzone <- "Etc/GMT+8"
  
  #detects_new1 <- detects[0,]
  #detects_new1 <- bind_rows(detects_new1, detects_new[,c("recv", "TagCode", "DateTime_Orig", "DateTime_PST")])
  detects_new <- merge(detects_new, gen_locs[,c("recv", "location", "general_location", "latitude", "longitude", "rkm")])
  detects <- rbind(detects, detects_new[,c("recv", "DateTime_Orig", "TagCode", "DateTime_PST", "location", "general_location", "latitude", "longitude", "rkm")])

}

downloads <- rbind(downloads, downloads_new_all)

## Check for hourly download gaps ##
downloads$gapstart <- as.POSIXct(NA)
downloads$gapend <- as.POSIXct(NA)

downloads <- downloads[order(downloads$recv, downloads$start),]

for (j in 2:nrow(downloads)){
  if(downloads[j-1, "recv"] == downloads[j, "recv"] & difftime(downloads[j, "start"], downloads[j-1, "start"], units = "hours") > 1.25 )
  {downloads[j-1,"gapstart"] <- downloads[j-1, "end"]
  downloads[j-1,"gapend"] <- downloads[j, "start"]
  }
  if (downloads[j-1, "recv"] != downloads[j, "recv"] & difftime(Sys.time(), downloads[j-1, "start"], units = "hours") > 2.2) {
    downloads[j-1,"gapstart"] <- downloads[j-1, "end"]
    downloads[j-1,"gapend"] <- Sys.time()
  }
}

gaps <- downloads[is.na(downloads$gapstart) == F,]
gaps$gapstart <- as.POSIXct(gaps$gapstart,format = "%Y-%m-%d %H:%M:%S", tz = "Etc/GMT+8")
gaps$gapend <- as.POSIXct(gaps$gapend, format = "%Y-%m-%d %H:%M:%S", tz = "Etc/GMT+8")

gaps$gap_length_hours <- round(difftime(gaps$gapend, gaps$gapstart, units = "hours"), 0)
gaps$start <- NULL
gaps$end <- NULL

downloads$gapstart <- NULL
downloads$gapend <- NULL


#### As a preliminary cut to detection filter, here we say a tag has to have been detected three times throughout Sacramento array ####

tags <- sort(table(detects$TagCode), decreasing = T)
tags <- tags[tags>3]
detects_filtered <- detects[detects$TagCode %in% rownames(tags),]
detects_filtered <- detects_filtered[order(detects_filtered$general_location, detects_filtered$TagCode, detects_filtered$DateTime_PST),]

#### Now, subset for only tags known to be in the system and with 2 or more detects per gen loc within 24 hours, by studyID

for (k in unique(tagcodes$StudyID)){
  studycodes <- tagcodes[tagcodes$StudyID == k, "TagID_Hex"]
  ## First, select only detections of correct tagcodes per study
  temp_detects <- as.data.frame(detects_filtered[detects_filtered$TagCode %in% studycodes,])
  if(nrow(temp_detects) > 0){
    ## Now create two columns with time in hours between the previous and next detection, for each detection
    temp_detects$time_to_next <- as.numeric(difftime(shift(temp_detects$DateTime_PST, fill = NA, type = "lead"), temp_detects$DateTime_PST, units = "hours"))
    temp_detects$time_from_previous <- as.numeric(difftime(temp_detects$DateTime_PST, shift(temp_detects$DateTime_PST, fill = NA, type = "lag"),  units = "hours"))
    ## Now make NA the time diff values when it's between 2 different gen locs or tagcodes
    temp_detects[which(temp_detects$general_location != shift(temp_detects$general_location, fill = NA, type = "lag")), "time_from_previous"] <- NA
    temp_detects[which(temp_detects$general_location != shift(temp_detects$general_location, fill = NA, type = "lead")), "time_to_next"] <- NA
    temp_detects[which(temp_detects$TagCode != shift(temp_detects$TagCode, fill = NA, type = "lag")), "time_from_previous"] <- NA
    temp_detects[which(temp_detects$TagCode != shift(temp_detects$TagCode, fill = NA, type = "lead")), "time_to_next"] <- NA
    ## Now pull out only tag detections that have another detection from the same tag at the same gen loc within 24 hours
    temp_detects <- temp_detects[which(apply(temp_detects[,c("time_to_next", "time_from_previous")],1,FUN=min, na.rm = T) < 24),]
    write.csv(temp_detects, paste(paste("detects",k,sep = "_"),".csv", sep = ""), row.names = F)
  }
}


latest <- as.character(round.POSIXt(max(downloads$end), units = "hour"))

## Now that all data manipulations are complete, export detcts with milliseconds shown (this turns the class into character)
detects$DateTime_PST <- format(detects$DateTime_PST, "%Y-%m-%d %H:%M:%OS6")

write.csv(latest, "latest_download.csv", row.names = F)
write.csv(downloads, "downloads.csv", row.names = F)
fwrite(detects, "detects_final.csv", row.names = F)
#write.csv(detects_filtered, "detects_filtered.csv", row.names = F)
write.csv(gaps, "download_gaps.csv", row.names = F)
write.csv(corrupted_downloads, "corrupted_downloads.csv", row.names = F)

#ATS_processed_files <- rbind(ATS_processed_files, ATS_files)
#write.csv(ATS_processed_files, "ATS_processed_files.csv", row.names = F)
TECKNO_processed_files <- rbind(TECKNO_processed_files, TECKNO_files)
write.csv(TECKNO_processed_files, "TECKNO_processed_files.csv", row.names = F)  




```
*Data current as of `r latest`*

<br/>

## Receiver sites
``` {r print site stats, echo=FALSE, warning=FALSE}

kable(gen_locs, align = "c")


````

<br/>

## Most recent downloads
``` {r print most recent downloads, echo=FALSE, warning=FALSE}

if (nrow(downloads_new_all) > 0) {
  downloads_new_all <- downloads_new_all[,c("recv", "start", "end", "location",
                                            "sun_volts", "bat_volts")]
  kable(downloads_new_all, row.names = F)
} else {
  "No new downloads"
}

````

<br/>

## Download gaps

```{r print gaps data, echo=FALSE, warning=FALSE}
kable(gaps[,-which(names(gaps) %in% c("hour", "sun_volts", "bat_volts", "latitude", "longitude", "rkm"))], row.names = F)
```


<br/>

## Corrupted Downloads

```{r print incomplete downloads}

colnames(corrupted_downloads) <- "Filename"

kable(corrupted_downloads, row.names = F)
```


